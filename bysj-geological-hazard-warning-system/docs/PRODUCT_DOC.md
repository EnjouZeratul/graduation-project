# 产品文档：地质灾害智能预警系统

本文档面向项目答辩/汇报/产品评审场景，侧重阐明“做什么、为谁做、解决什么问题、核心功能、需求拆解与创新点”，不展开代码实现细节（实现细节见 `docs/TECHNICAL_DOC.md`）。

> 用途声明：本项目仅用于学习、教学、科研与技术交流，不得用于商业化运营、数据转售、付费服务或其他盈利目的。第三方平台调用需遵守其服务条款与法律法规。

---

## 1. 背景与问题

地质灾害（滑坡、泥石流、崩塌、地面塌陷等）具有突发性与强破坏性，预警依赖气象触发条件、地质易发性、历史风险压力与空间关联影响。现实问题包括：
- 数据来源分散：官方数据权威但接口申请周期长；非官方信息更及时但可靠性参差。
- 决策链条难解释：单一阈值或单一模型难兼顾“准确性、可解释性、可扩展性”。
- 成本与实时性矛盾：纯 LLM 决策成本高且不可控；纯规则又容易失真。
- 可视化与协作困难：需要“按地区”呈现风险，并能在刷新过程中逐步更新。

本系统目标是在可控成本与合规前提下，提供“分区风险可视化 + 可解释预警 + 多源融合 + 可扩展架构”。

---

## 2. 产品定位

**定位**：面向全国/多地区的地质灾害风险预警与决策可视化平台。  
**核心价值**：让用户用最少的操作和等待，看到“哪里风险更高、为什么更高、置信度是多少、最可能发生什么类型灾害、数据是否可靠”。

---

## 3. 目标用户与使用场景

**目标用户**
- 研究/教学：地质灾害预警算法、数据融合、智能体工作流演示。
- 业务试点：应急/基层单位的预警研判辅助、汇报展示。
- 研发与运维：后续接入官方 API、多源扩展与数据治理。

**典型场景**
- 1) 日常监测：地图查看全国风险分布，重点关注橙/红区域。
- 2) 研判复核：点击某地区查看原因、置信度依据、可能灾害类型。
- 3) 临时加密刷新：在极端天气前手动触发主动刷新，快速更新热点区域。
- 4) 调试联调：无需等待真实数据源，使用“随机模拟”快速验证 UI 与链路。

---

## 4. 功能需求（按模块）

### 4.1 地图可视化
- 全国城市级区域边界展示，按风险等级上色（清晰边界 + 渐变/立体感）。
- tooltip 展示：地区名、风险等级、置信度。
- 点击地区进入“地区详情”。

### 4.2 预警列表与自动弹出
- 侧栏展示最新预警列表。
- 自动弹出策略：仅对 **橙/红（较高风险/高风险）** 自动强调，低风险/较低风险只在地图和详情中展示。

### 4.3 地区详情（可解释）
点击地区后展示：
- 风险等级、置信度（百分比）。
- 最新预警原因（中文且降噪）。
- **可能灾害类型**（如：滑坡、泥石流、崩塌、地面塌陷）。
- 置信度依据：计算方式/拆解项（质量分、变化分、数据源覆盖、阈值距离、邻区修正、LLM 修正等）。

### 4.4 刷新与实时更新
- **主动刷新**：默认快速模式，降低爬虫风险与等待时间。
- **全量刷新**：用户手动触发，覆盖全部地区。
- **中止**：允许用户中止长时间任务，已处理部分保留并实时推送。
- **实时推送**：刷新过程中分批推送增量结果，前端逐步更新，不需要等全部完成。
- **进度可见**：前端显示“本次计划/已处理/已运行秒数”，提升可控感与可解释性。
- **状态保留**：快速刷新只处理部分地区时，未处理地区维持上轮有效状态，避免出现“剩余地区被刷绿”的误导。

### 4.5 AI 问答（地区上下文）
- 在地区详情中提供“AI 问答”输入框。
- 问答仅围绕当前地区的最新风险、原因与关键指标给出简洁中文建议。

### 4.6 多源数据与合规爬虫（可扩展）
数据源策略：
- 官方 API（CMA/CGS 等）作为权威主源（拿到 key 后启用）。
- 国家气象（CMA）属于“站点观测接口（按 Station_Id_C 查询）”，系统通过“行政区坐标 -> 最近台站”离线生成映射文件实现对齐（可审计、可手工 overrides）。
- 高德天气（AMap）作为可用的补充源（实况无 mm 降雨时采用“估算降雨”并明确标注，且不会覆盖真实 mm 数据）。
- Weather Underground（weather.com API）作为补充源：按经纬度查询实况，支持后台自动发现并缓存 key；失效自动回退，不阻塞主流程。
- 非官方站点爬虫作为辅助源（白名单 + 限速 + 缓存 + 预算 + 政府域名阻断）。
- 多源同时获取与融合；当某源缺失/报错时，尽量沿用上轮有效观测，避免缺失覆盖导致全绿。
- Redis 持久化缓存：对 WU key 与地区级补充源数据做持久化，容器重启后仍可复用，降低冷启动外网压力与风控风险。

---

## 5. 核心创新点

### 5.1 多智能体工作流（LangGraph）用于“可控成本的分阶段决策”
- 先做本地计算（风险分与置信度）作为主判断，降低 token。
- 仅在“变化大/低置信度/强制触发”的小集合上使用 LLM 轻量复核，避免全量调用。
- 形成“可解释链条”：数据质量 -> 变化检测 -> 邻区影响 -> LLM 精修（可选）。

### 5.2 置信度可解释化（不是单一概率）
置信度不仅给数值，还提供“依据与拆解”，让用户知道：
- 数据是否完整（源覆盖、质量分）
- 是否接近阈值（更不确定）
- 是否变化剧烈（更不稳定）
- 邻区影响与 LLM 是否参与修正

### 5.3 增量推送 + 可中止的批次处理
将全量任务拆成批次（batch）：
- 批次完成即入库并推送，前端“边跑边看到结果”。
- 中止时保留已处理部分，避免长任务“等很久却一无所获”。

### 5.4 爬虫合规与“防串数据”机制
除基础限速与白名单外，额外引入：
- 政府域名阻断，降低法律风险。
- URL collision 防护：避免多个地区错误映射到同一页面导致“串数据”和“打爆站点”。
- overrides 映射机制：对易歧义地区进行人工修正，提高全国覆盖稳定性。

### 5.5 快速模式“批次轮换覆盖”
快速刷新不是永远刷新固定前 N 个地区：
- 每次刷新会覆盖一组高风险头部，并对其余地区进行轮换抽样。
- 多次快速刷新可逐步逼近全量覆盖，同时显著降低 403/封控风险。

### 5.6 展示去噪与用户理解优化
- 用户可见文本统一中文，避免中英混杂。
- 风险原因中的冗余技术片段做前端降噪（例如内部错误计数、英文残留片段）。
- “可能灾害”只保留一个展示入口，减少重复描述带来的认知负担。

---

## 6. 关键约束与非功能需求

- **中文一致性**：用户可见文本全部中文（原因/提示/字段）。
- **实时性**：支持主动刷新 + 被动定时刷新（默认每 30 分钟）。
- **稳定性**：任务超时尽量保留已完成部分；运行锁/心跳避免“假运行”。
- **合规与安全**：爬虫仅抓非政府白名单域名，遵守 robots/ToS；限速、缓存、窗口预算控制请求压力。
- **可扩展**：新增数据源不应大范围改动；对接官方 API 时以统一字段规范接入。

---

## 7. 当前状态与后续路线

**已具备**
- 地图风险展示、橙/红自动强调、地区详情可解释（置信度拆解与候选灾害）。
- 主动/全量刷新 + 中止 + 增量推送。
- 多源融合框架与爬虫安全护栏。
- 随机模拟（不入库）用于快速联调。

**后续可迭代**
- 官方 CMA/CGS API 接入后，提升权威性与覆盖指标（地质易发性、历史灾害事件等）。
- 更精细的空间邻接（行政相邻/水系/地形连通）替代当前近似邻区策略。
- 更强的“变化检测”：仅对变化地区触发 LLM，进一步降低成本。
